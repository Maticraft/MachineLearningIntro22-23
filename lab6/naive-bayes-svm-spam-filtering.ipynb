{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f169d7cf-818b-4815-a5be-76265e99d139",
    "_uuid": "25f02ffdb0d53b9663f351fa0c0f415d2bce15b1"
   },
   "source": [
    "#  Spam classification with Naive Bayes and Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook adapted from https://www.kaggle.com/code/pablovargas/naive-bayes-svm-spam-filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICS INTRO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.\n",
    "\n",
    "Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another). In particular, the actual names for the fields of the matrix are:\n",
    "\n",
    "* True Positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "* True Negatives (TN): We predicted no, and they don't have the disease.\n",
    "* False Positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "* False Negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")\n",
    "\n",
    "Table of confusion matrix terms\n",
    "\n",
    "| | Predicted Positive | Predicted Negative |\n",
    "| --- | --- | --- |\n",
    "| **Actual Positive** | True Positive (TP) | False Negative (FN) |\n",
    "| **Actual Negative** | False Positive (FP) | True Negative (TN) |\n",
    "\n",
    "\n",
    "#### Precision\n",
    "\n",
    "Precision is the fraction of relevant instances among the retrieved instances. It is defined as the number of true positives divided by the sum of true positives and false positives.\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "#### Recall\n",
    "\n",
    "Recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. It is defined as the number of true positives divided by the sum of true positives and false negatives.\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "\n",
    "Graphically, the confusion matrix, precision and recall can be visualized as follows:\n",
    "\n",
    "![Confusion Matrix](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png)\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall. It is defined as the number of true positives divided by the sum of true positives and half the sum of false positives and false negatives.\n",
    "\n",
    "The exact equation is:\n",
    "\n",
    "$$F1 = 2 \\frac{precision \\times recall}{precision + recall}$$\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "Accuracy is the fraction of predictions our model got right. It is defined as the number of true positives and true negatives divided by the total number of predictions.\n",
    "\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba30922b-183b-4f2e-ac19-35ebc9dd865a",
    "_uuid": "e27ea858875f6d5698fcfb196b32160c8d761697"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "77dbf249-4662-4faf-ae30-654f5f76f5b1",
    "_uuid": "5eb96b9e55cca9f7dbc74128cd5933856b39aa51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ab7471a7-9fda-4dc9-ba8b-6d4f0c1b92e1",
    "_uuid": "2a11f84b23cf786579a3beb1074c6e7375456b77"
   },
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e8604809-62b9-47bd-84fa-92063d8ae5b3",
    "_uuid": "3a9038c1ea6026f8ae89cf052aa71c89bcb940dd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6887a2a9-6c4c-42f1-92df-fdec4ae3f9f0",
    "_uuid": "47d3122a6fe0ed51dbe5775c7549695cce2a8470"
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "238e6b23-de89-4334-80d9-1662dfc1a211",
    "_uuid": "93273550c383144e9ddec84b179475ea7d9cb85c"
   },
   "source": [
    "Text preprocessing, tokenizing and filtering of stopwords are included in a high level component that is able to build a dictionary of features and transform documents to feature vectors.<p>\n",
    "**We remove the stop words in order to improve the analytics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "653bfeae-e298-44e3-b92c-78c0f747b8ef",
    "_uuid": "67b9147f254e720b0641d9a171333942ef529aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8404)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
    "X = f.fit_transform(data[\"v2\"])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "205a78b4-b452-4a1a-8912-de897a798097",
    "_uuid": "35e5277996ce60e9e8725e20805b2a0d7d118764"
   },
   "source": [
    "We have created more than 8400 new features. The new feature $j$ in the row $i$ is equal to 1 if the word $w_{j}$ appears in the text example $i$. It is zero if not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "448eda90-2493-46f0-a588-8e6e73b7e2d3",
    "_uuid": "1f0489faa50638217e4754ff0a8f26e5298752df"
   },
   "source": [
    "## Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1e8c9ef-588e-4708-8275-bfafe82c5cd8",
    "_uuid": "83edda58f114f466bf6cf6d1a278a1e5af08e651"
   },
   "source": [
    "First we transform the variable spam/non-spam into binary variable, then we split our data set in training set and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "e5e2bee3-cdad-4ee6-9c59-f3a536195ed7",
    "_uuid": "ab65abc5fe63168bfea503db8e58e5ab03383a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4457, 8404), (1115, 8404)]\n"
     ]
    }
   ],
   "source": [
    "data[\"v1\"]=data[\"v1\"].map({'spam':1,'ham':0})\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['v1'], test_size=0.2, random_state=42)\n",
    "print([np.shape(X_train), np.shape(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "76cc3deb-7b7c-4511-ae4e-ef5cd2f7592b",
    "_uuid": "0463069f7287a20571ab90885b85dad8d9a64368"
   },
   "source": [
    "### Multinomial naive bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "691fa70e-6aa0-4743-b948-650e90f61e40",
    "_uuid": "7146dbec1c30fd6f2c39454834281e7b74648f39"
   },
   "source": [
    "We train different bayes models changing the regularization parameter $\\alpha$. <p>\n",
    "We evaluate the accuracy, recall and precision of the model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "e7b5bbc6-23cb-49f8-8ea3-83f71c9f6d97",
    "_uuid": "4bf729b41f966730729d72d6b61e287ab426bd39",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_alpha = np.arange(1/100000, 20, 0.11)\n",
    "score_train = np.zeros(len(list_alpha))\n",
    "score_test = np.zeros(len(list_alpha))\n",
    "recall_test = np.zeros(len(list_alpha))\n",
    "precision_test= np.zeros(len(list_alpha))\n",
    "f1_test = np.zeros(len(list_alpha))\n",
    "count = 0\n",
    "for alpha in list_alpha:\n",
    "    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    bayes.fit(X_train, y_train)\n",
    "    score_train[count] = bayes.score(X_train, y_train)\n",
    "    score_test[count]= bayes.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n",
    "    f1_test[count] = metrics.f1_score(y_test, bayes.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4390a64a-41a8-46a6-b6bb-a204e769a617",
    "_uuid": "2c9003728118d2729d284b1712b85f0d2a4df3d5"
   },
   "source": [
    "Let's see the first 10 learning models and their metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "9bb5c44b-9d9b-4f79-8462-324eb3addcad",
    "_uuid": "b38a2e021e3b5898e0883ee95165457af85f954b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998205</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.907895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.11001</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.909677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22001</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.891720</td>\n",
       "      <td>0.912052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33001</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.880503</td>\n",
       "      <td>0.906149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44001</td>\n",
       "      <td>0.995961</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.892405</td>\n",
       "      <td>0.915584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55001</td>\n",
       "      <td>0.995513</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.908497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.66001</td>\n",
       "      <td>0.995513</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.920530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.995288</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.923588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.88001</td>\n",
       "      <td>0.995064</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.923588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99001</td>\n",
       "      <td>0.995064</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.923588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha  Train Accuracy  Test Accuracy  Test Recall  Test Precision  \\\n",
       "0  0.00001        0.998205       0.974888     0.920000        0.896104   \n",
       "1  0.11001        0.997083       0.974888     0.940000        0.881250   \n",
       "2  0.22001        0.997083       0.975785     0.933333        0.891720   \n",
       "3  0.33001        0.996186       0.973991     0.933333        0.880503   \n",
       "4  0.44001        0.995961       0.976682     0.940000        0.892405   \n",
       "5  0.55001        0.995513       0.974888     0.926667        0.891026   \n",
       "6  0.66001        0.995513       0.978475     0.926667        0.914474   \n",
       "7  0.77001        0.995288       0.979372     0.926667        0.920530   \n",
       "8  0.88001        0.995064       0.979372     0.926667        0.920530   \n",
       "9  0.99001        0.995064       0.979372     0.926667        0.920530   \n",
       "\n",
       "   Test F1 Score  \n",
       "0       0.907895  \n",
       "1       0.909677  \n",
       "2       0.912052  \n",
       "3       0.906149  \n",
       "4       0.915584  \n",
       "5       0.908497  \n",
       "6       0.920530  \n",
       "7       0.923588  \n",
       "8       0.923588  \n",
       "9       0.923588  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test, f1_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision', 'Test F1 Score'])\n",
    "models.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "072aeed4-d578-4917-b32e-ca54380dd5e2",
    "_uuid": "7a3bfc6ad5f9e5d05187c61074b1b47b50516772"
   },
   "source": [
    "I select the model with the highest F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "6f285b74-00bc-45cd-af8c-ac3c846b92e7",
    "_uuid": "4d87a52c2e11585c970314171d943bcb45f596c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha             3.080010\n",
       "Train Accuracy    0.991698\n",
       "Test Accuracy     0.983857\n",
       "Test Recall       0.913333\n",
       "Test Precision    0.964789\n",
       "Test F1 Score     0.938356\n",
       "Name: 28, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index = models['Test F1 Score'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "67ca2aef-56b9-4701-9590-387eb64c13a8",
    "_uuid": "606304507b731dd866ad9b97daa654a0c32a544a"
   },
   "source": [
    "#### Confusion matrix with naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "076b7447-5c33-4671-8b25-7000e0c3a28f",
    "_uuid": "a700b298131b18e8ec21a67959df4a71c1177a54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>38</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          965            0\n",
       "Actual 1           38          112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "edfcb798-4f74-4552-8bea-2617804eea56",
    "_uuid": "63efdf82c6e3aeabf14cc906cec456ba6f6a6ac0"
   },
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Quick introduction to SVM\n",
    "\n",
    "Support Vector Machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "* Effective in high dimensional spaces.\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "* If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.\n",
    "\n",
    "#### Support vectors\n",
    "\n",
    "The main idea behind support vector machines is to find a hyperplane that best separates the classes. The hyperplane is defined by the equation:\n",
    "\n",
    "$$w^Tx + b = 0$$\n",
    "\n",
    "where $w$ is the normal vector to the hyperplane and $b$ is the bias. The hyperplane is the line that separates the classes. The support vectors are the data points that are closest to the hyperplane. The distance between the hyperplane and the support vectors is called the margin. The goal is to maximize the margin.\n",
    "\n",
    "![Support vectors visualization](https://static.wixstatic.com/media/8f929f_7ecacdcf69d2450087cb4a898ef90837~mv2.png)\n",
    "\n",
    "\n",
    "#### Kernel functions\n",
    "\n",
    "In case of linearly inseparable data, we can use a kernel function to transform the data into a higher dimensional space. In this space, the data is linearly separable. The kernel function is used to compute the dot product of two vectors in a higher dimensional space. The kernel function is defined as:\n",
    "\n",
    "$$K(x, y) = \\phi(x)^T \\phi(y)$$\n",
    "\n",
    "where $\\phi(x)$ is a mapping from the original space to a higher dimensional space.\n",
    "\n",
    "The most common kernel functions are:\n",
    "\n",
    "* Linear kernel: $K(x, y) = x^T y$\n",
    "* Polynomial kernel: $K(x, y) = (x^T y + c)^d$\n",
    "* Radial basis function (RBF) kernel: $K(x, y) = \\exp(-\\gamma \\|x - y\\|)$$\n",
    "* Sigmoid kernel: $K(x, y) = \\tanh(\\gamma x^T y + r)$\n",
    "\n",
    "\n",
    "![Kernel](https://miro.medium.com/max/838/1*gXvhD4IomaC9Jb37tzDUVg.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the SVM model\n",
    "\n",
    "We train different models changing the regularization parameter C. <p>\n",
    "We evaluate the accuracy, recall and precision of the model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "f82fc85a-e883-42d1-abbc-c3b3342247dc",
    "_uuid": "1101b49ede4dccec53089e86f3db2969abea67ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_C = np.arange(500, 2000, 100) #100000\n",
    "score_train = np.zeros(len(list_C))\n",
    "score_test = np.zeros(len(list_C))\n",
    "recall_test = np.zeros(len(list_C))\n",
    "precision_test= np.zeros(len(list_C))\n",
    "f1_test= np.zeros(len(list_C))\n",
    "count = 0\n",
    "for C in list_C:\n",
    "    svc = svm.SVC(C=C, kernel='rbf')\n",
    "    svc.fit(X_train, y_train)\n",
    "    score_train[count] = svc.score(X_train, y_train)\n",
    "    score_test[count]= svc.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, svc.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(y_test, svc.predict(X_test))\n",
    "    f1_test[count] = metrics.f1_score(y_test, svc.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "820fad12-6a0e-4ec6-b16a-e9734d69bf64",
    "_uuid": "4e1c88cc318233afe97fa9e298562c1e6025de1d"
   },
   "source": [
    "Let's see the first 10 learning models and their metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4da69237-fe8c-40ac-a72a-d33dc7863859",
    "_uuid": "ec36f5defc3f1477cca07c5280818ee4282995d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.901818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  Train Accuracy  Test Accuracy  Test Recall  Test Precision  \\\n",
       "0   500.0             1.0       0.975785     0.826667           0.992   \n",
       "1   600.0             1.0       0.975785     0.826667           0.992   \n",
       "2   700.0             1.0       0.975785     0.826667           0.992   \n",
       "3   800.0             1.0       0.975785     0.826667           0.992   \n",
       "4   900.0             1.0       0.975785     0.826667           0.992   \n",
       "5  1000.0             1.0       0.975785     0.826667           0.992   \n",
       "6  1100.0             1.0       0.975785     0.826667           0.992   \n",
       "7  1200.0             1.0       0.975785     0.826667           0.992   \n",
       "8  1300.0             1.0       0.975785     0.826667           0.992   \n",
       "9  1400.0             1.0       0.975785     0.826667           0.992   \n",
       "\n",
       "   Test F1 Score  \n",
       "0       0.901818  \n",
       "1       0.901818  \n",
       "2       0.901818  \n",
       "3       0.901818  \n",
       "4       0.901818  \n",
       "5       0.901818  \n",
       "6       0.901818  \n",
       "7       0.901818  \n",
       "8       0.901818  \n",
       "9       0.901818  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.matrix(np.c_[list_C, score_train, score_test, recall_test, precision_test, f1_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision', 'Test F1 Score'])\n",
    "models.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d5e554d-e0d8-44b0-9fca-480063caf529",
    "_uuid": "17a895a4c6a415493afae69ebeff7d172f09b014"
   },
   "source": [
    "I select the model with the highest F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d0380748-44f5-4e41-af56-d25230c44479",
    "_uuid": "45c5f185a965f1b92889e56ce5f12c7acacffdf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C                 500.000000\n",
       "Train Accuracy      1.000000\n",
       "Test Accuracy       0.975785\n",
       "Test Recall         0.826667\n",
       "Test Precision      0.992000\n",
       "Test F1 Score       0.901818\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index = models['Test F1 Score'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d41fbc97-15f5-4963-9d5f-1452b2efe7ab",
    "_uuid": "dd004721e1b6171488e1acf4c2a14235fc7f9700"
   },
   "source": [
    "#### Confusion matrix with support vector machine classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "bf03b698-42e2-407f-a3da-dcc4acc36221",
    "_uuid": "77005bd9a0fd6de323ada9206468c0598fa9c476"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>26</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          964            1\n",
       "Actual 1           26          124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, svc.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use custom kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9802690582959641\n",
      "Test F1 score: 0.9214285714285715\n"
     ]
    }
   ],
   "source": [
    "# Let's try to use custom kernel\n",
    "def my_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)\n",
    "\n",
    "svc = svm.SVC(kernel=my_kernel)\n",
    "svc.fit(X_train, y_train)\n",
    "print('Test accuracy:', svc.score(X_test, y_test))\n",
    "print('Test F1 score:', metrics.f1_score(y_test, svc.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.4 ('ML_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "929619df38edafcb639067bc1593fc1a1a9b049525cf7e96331131a0abd5060a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
